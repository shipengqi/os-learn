# 虚拟化

什么是虚拟化？

假设有一个桃子，这是真实的桃子，称为物理桃子。很多人想吃这个桃子，如果要给每个人一个属于他们自己的桃子，把给每个人的桃子称为虚拟桃子。通过某种方式从物理桃子创造出的许多虚拟桃子，在这种假象中，每个人看起来都有一个物理桃子，实际上不是。每个人都不知道在和别人分享同一个物理桃子。

以 CPU 为例，虚拟化做的就是将计算机的 CPU 虚拟成多个 CPU 并分给每个进程使用，因为每个进程都以为自己在独占 CPU，实际上只有一个 CPU。

## 进程

程序本身没有生命周期，它只是存储在磁盘上的一些指令或数据。**进程就是运行中的程序**。物理机上只有少量的 CPU，操作系统如何实现有无数个 CPU 的假象？

虚拟化 CPU，通过让一个进程只运行一个时间片，然后切换到其他进程。这就是**时分共享** CPU 技术。CPU 由于被共享，那么每个进程的运行就会慢一点。

### 进程 API

`fork()` 和 `exec()` 这两个系统调用可以创建新的进程。

#### fork

系统调用 fork 创建新进程，但是这个接口非常奇怪。

```c
printf("hello world (pid:%d)\n", (int) getpid());
int rc = fork();
if (rc < 0) {
    fprintf(stderr, "fork failed\n");
    exit(1);
} else if (rc == 0) {
    printf("hello, I am child (pid:%d)\n", (int) getpid());
} else {
    printf("hello. I am parent of %d (pid:%d)\n", rc, (int) getpid());
}
```

输出：

```bash
hello world (pid:29146)
hello. I am parent of 29147 (pid:29146)
hello, I am child (pid:29147)
```

第一行输出的是当前进程 PID。然后使用 fork 创建了新的进程（子进程），新的进程几乎与调用进程（父进程）完全一样，在操作系统看来有两个完全一样的程序在运行，并都从 fork 系统调用中返回。子进程不会从 main 函数开始执行（hello world 只输出了一次），而是从 fork 返回，好像是它自己调用了 fork。

子进程并不是完全拷贝了父进程，子进程拥有独立的地址空间，寄存器等，但是它从 fork 返回的值是不同的。**子进程得到的返回值是 0，父进程得到的返回值是子进程的 PID**。

如果在单个 CPU 的系统上运行，父子这两个进程的运行顺序是不确定的。

#### wait

wait 会等待子进程运行

#### exec

exec 系统调用也是创建进程，不过它可以运行与父进程不同的程序。exec 指定可执行程序和参数，exec 会从可执行程序中加载代码和静态数据，并用它复写自己的代码段，堆、栈及其他内存空间都会被重新初始化。然后操作系统执行该程序，传入参数。因此它并没有创建新的进程，而是直接将当前运行的程序换位不同的运行程序。

#### fork 和 exec

fork 和 exec 这中设计，使 shell 在 fork 之后和 exec 之前可以执行代码的机会，可以在运行新程序前改变环境。

#### shell 如何运行一条命令

1. shell 也是一个程序，它首先显示一个提示符，等待用户输入。
2. 当用户输入某条命令时，shell 会在文件系统中找到这个可执行程序，调用 fork 创建新进程
3. 调用 exec 的某个变体来执行这个可执行程序
4. 调用 wait 等待命令执行完成
5. 子进程结束后，shell 从 wait 返回并输出一个提示符，等待用户的下一个输入。

fork 和 exec 分离的设计可以实现很多功能：`wc p1.c > output.txt`。

上面的例子中，shell 创建子进程，在调用 exec 之前，关闭了标准输出，打开 `output.txt` 文件，使 wc 的输出被发送到了文件，而不是标准输出。

虚拟化 CPU 是通过时分共享实现的，但是这种机制要面对两个问题：

1. 性能，如何实现不增加系统开销的情况下实现虚拟化？
2. 如何有效的运行进程，同时保留系统对 CPU 的控制权？因为操作系统负责资源管理，如果没有控制权，一个进程就可以无限制的运行，或者访问没有权限的信息。

#### 受限制的操作

用户模式下，进程不能完全访问硬件资源。操作系统运行在内核模式下，此模式下可以访问机器的全部资源。用户程序可以通过内核提供的系统调用，来执行特权操作，如访问文件系统，创建销毁进程，进程间通信等。

要执行系统调用，进程必须执行特殊的**陷阱**（`trap`）指令。该指令跳入内核并将特权级别提升到内核模式。完成后，操作系统调用**陷阱返回**（`return-from-trap`）指令，返回到发起调用的用户程序中，同时将特权降级到用户模式。

trap 是一种中断，当用户态程序发起系统调用时，用户态程序权限不足，因此 trap 中断执行，中断发生后，当前 CPU 执行的程序会中断，跳转到中断处理程序。内核开始执行，也就是开始处理系统调用。内核处理完成后，再次出发 trap，切换到用户态。

#### 进程间切换

一个 CPU 如果正在运行一个进程，那么意味这操作系统没有运行，操作系统如何获得 CPU 的控制权？

协作方式，等待系统调用，陷入内核，操作系统可以获取 CPU 控制权。

非协作方式，如果某个进程不进行系统调用，就需要**时钟中断**。时钟设备可以每隔几毫秒产生一次中断，操作系统的中断处理程序就会运行，此时操作系统重新获得 CPU 的控制权。然后操作系统可以停止一个进程，启动另一个进程。这属于硬件功能。

#### 中断的设计

以键盘为例，按键码的收集，是键盘芯片和主板的能力。主板知道有新的按键后，通知 CPU，CPU 要中断当前执行的程序，将 PC 指针跳转到一个固定的位置，称为一次**中断**（interrupt）。

CPU 中断正在执行的程序，然后切换到另一个需要执行的程序。说白了就是改变 PC 指针，CPU 只有这一种办法切换执行的程序。

CPU 怎么知道 PC 指针应该设置为多少呢？是不是 CPU 知道操作系统响应按键的程序位置呢？

当然是不知道。因此，我们只能控制 CPU 跳转到一个固定的位置。

系统中会出现各种各样的事件，需要根据中断类型来判断 PC 指针跳转的位置，中断类型不同，跳转的位置也可能不同。不同的中断类型叫做**中断识别码**。比如按键的中断识别码是 16。不同的中断发生时，CPU 需要知道 PC 指针跳转的地址，这个地址叫做**中断向量**。一个中断向量占据 4 字节空间。当编号 16 的中断发生时，32 位机器的 PC 指针直接跳转到内存地址 `16*4` 的内存位置。如果最多有 255 个中断，编号就是 `0~255`，刚好需要 1 KB 的内存地址存储中断向量，这 1 KB 的空间，叫做**中断向量表**。

因此 CPU 收到中断后，根据中断类型操作 PC 指针，找到中断向量。操作系统必须在这之前，修改中断向量，插入一条指令。比如操作系统在这里写入一条 `Jump` 指令，将 PC 指针再次跳转到自己处理对应的中断处理程序。

为了在发生中断时 CPU 能够及时执行对应的中断处理程序，系统所有的中断处理程序都预先加载到内存，存放在不同的区域，入口地址也不同。中断处理程序的入口地址就是**中断向量**。系统在内存中建立了一个中断向量表，存储所有的中断向量。

CPU 只要根据中断号查表，就可获得对应的中断向量，并转去执行中断服务程序。

中断向量是一个逻辑地址，包含段地址和偏移地址，长度为 4 字节。为了确保 CPU 查表成功，中断向量表在内存中的存储位置是固定的，每次开机，系统启动程序都会自动将中断向量表装入内存物理地址为 `0~1023` 的 1 KB 空间中（也就是内存中地址最低的 1 KB 空间）。

##### 保存和恢复上下文

操作系统获得了控制权以后，无论是通过系统调用协作还是时钟中断，都必须由调度程序决定切换到哪个进程。

切换进程，OS 就会执行一些底层代码，即**上下文切换**。

上下文切换：操作系统为当前执行的进程保存一些寄存器的值到它的内核栈，并且为即将执行的进程把保存在内核栈中的寄存器值恢复到寄存器。

### 进程调度

`周转时间 = 完成时间 - 到达时间`

任务的周转时间等于任务完成时间减去任务到达系统的时间。

#### 先进先出

FIFO

#### 最短任务优先

SJF 是非抢占式的

#### 最短完成时间优先

最短完成时间优先（STCF）就是在 SJF 的基础上添加了抢占

#### 响应时间

如果任务只使用 CPU，那么唯一得衡量是周转时间，STCF 是一个很好的策略。

响应时间定义为从任务到达系统到首次运行的时间。

`响应时间 = 首次运行 - 到达时间`

#### 轮转

轮转（Round-Robin，RR）调度算法的思想很简单：RR 在一个时间片（time slice，也叫做调度量子）内运行一个工作，然后切换到下一个运行队列中的任务，而不是运行一个任务直到结束。反复执行知道所有的任务完成。RR 有时被称为**时间切片**。时间片的长度必须是时钟中断周期的倍数，比如时钟中断间隔是 10ms，那么时间片长度可以是 10ms，20ms 等。

时间片长度越短，RR 在响应时间上越快。时间片太短也有问题，上下文切换的成本会影响整体性能。

上下文切换的成本不止是保存和回复寄存器的操作。程序运行是，在高速缓存，TLB 等建立了大量的状态，切换到另一个工作会导致这些状态丢失。

#### 结合 IO

### 多级反馈队列

对于 SJF 和 STCF 通过先执行最短完成时间的工作，但是操作系统通常不知道工作要运行多久，但这又是算法必需的。

轮转虽然降低了响应时间，但是周转时间却很差。

多级反馈队列（Multi-level Feedback Queue，MLFQ），要解决两个文图，优化周转时间和响应时间。

**MLFQ 中有许多独立的队列，每个队列有不同的优先级。一个工作只能存在于一个队列中。MLFQ 总是有限执行优先级高的队列中的工作。同一个队列中的工作有同样的优先级，这种情况下，采用轮转调度**。

MLFQ 的关键就在于如何设置**优先级**。MLFQ 会根据工作运行中的行为来调整优先级。如，一个工作不断放弃 CPU 去等待键盘的输入，那么就可能是交互型进程，会被保持高优先级。如果一个工作长时间占用 CPU，那么就会被降低优先级。MLFQ 就是在进程运行中学习其行为，预测未来的行为。

优先级调整规则：

- 规则 1：如果 A 的优先级 > B 的优先级，运行 A（不运行 B）。
- 规则 2：如果 A 的优先级 = B 的优先级，轮转运行 A 和 B。
- 规则 3：工作进入系统时，放在最高优先级（最上层队列）。
- 规则 4：工作用完整个时间片后，降低其优先级（移入下一个队列）。如果工作在其时间片以内主动释放 CPU，则优先级不变。一旦工作用完了其在某一层中的时间配额（无论中间主动放弃了多少次CPU），就降低其优先级（移入低一级队列）。
- 规则 5：经过一段时间 S，就将系统中所有工作重新加入最高优先级队列。解决了两个问题，首先，如果太多的交互型进程，就会不断占用 CPU，会导致长工作永远无法得到 CPU。所以这个规则，加入到最高级优先级队列，不会让长工作饿死。其次，

### 比例份额

比例份额调度程序，也叫做公平份额调度程序。目标就是确保每一个工作获得一定比例的 CPU 时间，而不是优化周转时间和响应时间。并没有被广泛应用。

### 多处理器调度

多核 CPU

单队列调度（Single Queue Multiprocessor Scheduling，SQMS）
多队列调度（Multi-Queue Multiprocessor Scheduling，MQMS）

## 内存

操作系统提供了一个物理内存抽象，**地址空间**。运行中的程序看到的系统内存就是地址空间。

### 内存操作 API

程序的内存一般分两种：

- 栈内存，一般由编译器自动分配和释放，存储函数的入参，局部变量，这些参数会随着函数的创建而创建，函数的返回而消亡，一般不会在程序中长期存在。
- 堆内存，在 C 中，由程序员显示的申请和释放，在 Go 中由内存分配器分配并由垃圾收集器负责回收。这是长期内存。

忘记分配内存，没有分配足够的内存，忘记初始化分配的内存，忘记释放内存，在用完之前释放内存（悬挂指针），反复释放内存

#### malloc

#### free

### 地址转换

基于硬件的**地址转换**，利用地址转换，硬件对每次内存访问进行处理（即指令获取。数据读取或写入），将指令中的虚拟地址转换为数据实际村吃的物理地址。因为每次内存引用时，硬件都会进行地址转换，将应用程序的内存引用重定位到内存中的实际位置。

硬件知识提供了底层机制来提高效率。操作系统也需要在关键位置介入，以便完成正确的地址转换。操作系统需要管理内存，记录被占用和空闲的内存，保持对内存使用的控制。

```c
void func() {
    int x;
    x = x + 3;
}
```

编译器将代码转为汇编：

```bash
128: movl 0x0(%ebx), %eax
132: addl $0x03, %eax
135: movl %eax, 0x0(%ebx)
```

假定变量 x 的地址已经存入寄存器 ebx，然后通过指令 movl 指令 将这个地址的值加载到通用寄存器 eax。下一条指令对 eax 中的值加 3.最后将 eax 中的值写回到内存的同意位置。

1. 从地址 128 获取指令
2. 执行指令（从地址 15KB 加载数据）
3. 从地址 132 获取命令
4. 执行命令
5. 从地址 135 获取指令
6. 执行指令（新值存入地址 15KB）

从程序角度来看，他的地址空间从 0 开始到 16KB 结束。它包含的所有的内存引用都应该在这个范围内。对于虚拟内存来说，操作系统将这个进程地址空间放在物理内存的其他位置，并不一定从地址 0 开始。

每个 CPU 需要两个硬件寄存器：**基址（base）寄存器**和**界限（bound）寄存器**，有时称为限制（limit）寄存器。这组基址和界限寄存器，让我们能够将地址空间放在物理内存的任何位置，同时又能确保进程只能访问自己的地址空间。

在编写和编译程序时假设地址空间从零开始。但是，**当程序真正执行时，操作系统会决定其在物理内存中的实际加载地址，并将起始地址记录在基址寄存器中**。`physical address = virtual address + base`。由于这种重定位是在运行时发生的，甚至可以在进程开始运行后改变其地址空间，这种技术一般被称为**动态重定位**。

上面的例子中，界限寄存器被置为 16KB。如果进程需要访问超过这个界限或者为负数的虚拟地址，CPU 将触发异常，进程最终可能被终止。界限寄存器的用处在于，它确保了进程产生的所有地址都在进程的地址“界限”中。

CPU 的这个负责地址转换的部分统称为**内存管理单元**（Memory Management Unit，MMU）

#### 操作系统的问题

1. 在进程创建时，操作系统为进程的地址空进找到内存空间，操作系统把整个物理内存看做一组槽块，标记空闲或已用。当创建新进程时，检索这个数据结构（空闲列表）为新地址空间找到位置，并标记已用。
2. 进程终止时，操作系统会后它的内存，放回到空闲列表，清除相关数据结构。
3. 上下文切换时，每个 CPU 只有一个基址寄存器和一个界限寄存器，对于每个运行的程序，他们的值是不同的。因此在切换时，操作系统必须保存和回复基址和界限寄存器的值。
4. 操作系统必须提供异常处理程序。

动态重定位技术有效率低下的问题。例如，重定位的进程使用了从 32KB 到 48KB 的物理内存，但由于该进程的栈区和堆区并不很大，导致这块内存区域中大量的空间被浪费。这种浪费通常称为**内部碎片**（internal fragmentation），指的是已经分配的内存单元内部有未使用的空间（即碎片），造成了浪费。所以，我们需要更复杂的机制，以便更好地利用物理内存，避免内部碎片。

### 分段

如果将整个地址空间放入物理内存，那么栈和堆之间的空闲空间没有被进程使用，却依然占用可实际的物理内存。因此，简单的通过基址寄存器和界限寄存器实现虚拟内存是很浪费的。

分段就是为了解决上面的问题。在 MMU 中引入不止一个基址和界限寄存器对，而是给地址空间内的每个**逻辑段**一对。一个段是地址空间里的一个连续定长的区域，典型的地址空间有三个逻辑段L代码，栈和堆。分段基址使操作系统能够将不同的段放到不同的物理内存区域，避免了虚拟地址空间中未使用部分占用物理内存。

### 空闲空间管理

### 分页

将空间分为固定长度的分片，这种思想叫做**分页**。分页不是将地址空间分割成几个不同长度的逻辑段，二十分割成固定大小的单元，每个单元称为一**页**。把物理内存看成是定长槽块的阵列，叫做**页帧**，每个页帧包含一个虚拟内存页。

假如一个需要 64 字节的地址空间（真是的地址空间是很大的，一般 32 位就有 4 GB 的地址空间），包含 4 个 16 自己的页，分别为虚拟页 0，1，2，3。物理内存，如图有 8 个页帧（128 字节）。虚拟内存页放在物理内存的不同位置。

![](/static/images/process-page.jpg)

为了记录地址空间的每个虚拟页存放在物理内存中位置，操作系统为每个进程保存一个数据结构，称为**页表**。页表的主要作用就是为地址空间的每个虚拟页面保存地址转换。

例如，一个 64 字节的小地址空间访问内存：`movl 21, %eax`。为了转换虚拟地址，将他分为两个部分，**虚拟页面号**（virtual page number，VPN），**页内偏移量**。64 字节的虚拟地址需要 6 位来表示，页面大小为 16 字节，64 字节的地址空间需要 4 个页，前 2 位就可以表示。将 31 变为二进制 `010101`，那么 `[01][0101]` 第一个 01 就表示虚拟页 01，0101 就表示第五个字节处。

得到虚拟页号，就可以检索页表得到虚拟页 01 所在的物理页面。结合上图就是物理帧号（PFN）7，偏移量不变，最终得到的物理地址是 1100101（117）。

![](/static/images/process-pfn.jpg)

一个典型的 32 位地址空间，带有 4KB 的页。这个虚拟地址分成 20 位的 VPN 和 12 位的偏移量。一个 20 位的 VPN 意味着，操作系统必须为每个进程管理 `2^20` 个地址转换（大约一百万）。假设每个页表格条目（PTE）需要 4 个字节，来保存物理地址转换和任何其他有用的东西，每个页表就需要巨大的4MB内存！这非常大。如果有 100 个进程在运行：这意味着操作系统会需要 400MB 内存。

分页会导致较慢的机器（有许多额外的内存访问来访问页表）和内存浪费（内存被页表塞满而不是有用的应用程序数据）。

#### 快速地址转换 TLB

使用分页作为核心机制来实现虚拟内存，可能会带来较高的性能开销。因为要使用分页，就要将内存地址空间切分成大量固定大小的单元（页），并且需要记录这些单元的地址映射信息。因为这些映射信息一般存储在物理内存中，所以在转换虚拟地址时，分页逻辑上需要一次额外的内存访问。每次指令获取、显式加载或保存，都要额外读一次内存以得到转换信息，这慢得无法接受。

地址转换旁路缓冲存储器（translation-lookaside buffer，TLB），它就是频繁发生的虚拟到物理地址转换的硬件缓存（cache），用来加速地址转换。

对每次内存访问，硬件先检查 TLB，看看其中是否有期望的转换映射，如果有，就完成转换（很快），不用访问页表（其中有全部的转换映射）。

#### 较小的表

页表太大，因此消耗的内存太多。

一种简单的方法减小页表大小：使用更大的页。再以 32 位地址空间为例，但这次假设用16KB的页。因此，会有 18 位的 VPN 加上 14 位的偏移量。假设每个页表项（4 字节）的大小相同，现在线性页表中有 218 个项，因此每个页表的总大小为 1MB，页表缩到四分之一。

然而，这种方法的主要问题在于，大内存页会导致每页内的浪费，这被称为内部碎片（internal fragmentation）。

**多级页表**（multi-level page table），它将线性页表变成了类似树的东西。首先将页表分成页大小的单元。如果整页的页表项（PTE）无效，就完全不分配该页的页表。为了追踪页表的页是否有效，使用了**页目录**结构。页目录可以告诉你页表的页在哪，或者页表的整个页是否有效。

### 交换空间

为了支持更大的地址空间，操作系统需要把没有用的那部分地址空间找个地方存储起来。硬盘就可以满足这个需求。

进程有了巨大的地址空间，就可以不需要关心程序的数据结构是否有足够的空间存储。操作系统提供了一个假象。

交换空间（swap space）就是在硬盘上开辟一部分空间用于物理也得移入和移出。

#### 交换策略
